{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ансамбль элементарных перцептронов на выборке MNIST"
      ],
      "metadata": {
        "id": "VdRPYInWvR4v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импортируем библиотеки"
      ],
      "metadata": {
        "id": "zk7te_o3vIuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "MsVH_VPoqp5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Реализуем класс Элементарного перцептрона с помощью библиотеки torch"
      ],
      "metadata": {
        "id": "iFV6A8_vvw_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron(torch.nn.Module):\n",
        "  def __init__(self, in_size, out_size):\n",
        "    super(Perceptron, self).__init__()\n",
        "\n",
        "    self.linerar_layer_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=in_size, out_features=out_size),\n",
        "        nn.Identity()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linerar_layer_stack(x)\n"
      ],
      "metadata": {
        "id": "UaJKra7Av3Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Реализуем функцию обучения"
      ],
      "metadata": {
        "id": "36GoDVDRwxHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, loss_func, optimizer, train_loader, test_loader, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    print(f'Epoch: {epoch}')\n",
        "    for batch_i, (data, target) in enumerate(train_loader):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      out = model(data)\n",
        "      loss = loss_func(out, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()"
      ],
      "metadata": {
        "id": "Kwker1E6xMYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Создаем датасеты"
      ],
      "metadata": {
        "id": "P4Tpb563yXaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "target_transform = lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)\n",
        "\n",
        "train_data = datasets.MNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=Lambda(target_transform)\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=Lambda(target_transform)\n",
        ")"
      ],
      "metadata": {
        "id": "2hefoV-VycxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6344d6c5-f5a4-4d39-dcee-b62753c711e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 34752682.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1047116.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 10150992.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 922409.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задаем параметры и загружаем датасеты"
      ],
      "metadata": {
        "id": "NPfM2KlWzJWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "lr = 0.03\n",
        "epochs = 20\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "Kpk0Ner8zOK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучаем модель"
      ],
      "metadata": {
        "id": "owqa9iYlzdtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Perceptron(28*28, 10)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "fit(model, loss_func, optimizer, train_loader, test_loader, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zjnajAMzluu",
        "outputId": "ce3da9dd-2858-4ffd-ecc1-b961cd1124b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Epoch: 1\n",
            "Epoch: 2\n",
            "Epoch: 3\n",
            "Epoch: 4\n",
            "Epoch: 5\n",
            "Epoch: 6\n",
            "Epoch: 7\n",
            "Epoch: 8\n",
            "Epoch: 9\n",
            "Epoch: 10\n",
            "Epoch: 11\n",
            "Epoch: 12\n",
            "Epoch: 13\n",
            "Epoch: 14\n",
            "Epoch: 15\n",
            "Epoch: 16\n",
            "Epoch: 17\n",
            "Epoch: 18\n",
            "Epoch: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Проверяем"
      ],
      "metadata": {
        "id": "bHHhjgNXz4-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_max_index(arr1,arr2):\n",
        "  return arr1.index(max(arr1)) == arr2.index(max(arr2))\n",
        "\n",
        "test_loss = 0.0\n",
        "acc = 0\n",
        "for data, target in test_loader:\n",
        "  output = model(data)\n",
        "  for i in range(len(data)):\n",
        "    if find_max_index(output[i].detach().numpy().tolist(), target[i].detach().numpy().tolist()):\n",
        "      acc += 1\n",
        "  test_loss += loss_func(output, target).item()\n",
        "\n",
        "print(f'Test loss: {test_loss/len(test_loader):.4f}')\n",
        "print(f'Accurancy: {acc/len(test_loader.dataset)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FW_TICg0Ht-",
        "outputId": "f220184c-7e7c-4ed5-c7db-a259d118c436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.2876\n",
            "Accurancy: 0.9191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UqledRgDIPFi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}